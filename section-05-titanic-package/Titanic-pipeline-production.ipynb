{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# ========== NEW IMPORTS ========\n",
    "# Respect to notebook 02-Predicting-Survival-Titanic-Solution\n",
    "\n",
    "# pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for the preprocessors\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# for imputation\n",
    "from feature_engine.imputation import (\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer,\n",
    "    CategoricalImputer,\n",
    ")\n",
    "\n",
    "# for encoding categorical variables\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OneHotEncoder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - it is available open source and online\n",
    "\n",
    "data = pd.read_csv('clf_model/datasets/train_titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace interrogation marks by NaN values\n",
    "\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the columns names\n",
    "data.columns = [var.lower() for var in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only the first cabin if more than\n",
    "# 1 are available per passenger\n",
    "\n",
    "def get_first_cabin(row):\n",
    "    try:\n",
    "        return row.split()[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "data['cabin'] = data['cabin'].apply(get_first_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the title (Mr, Ms, etc) from the name variable\n",
    "\n",
    "def get_title(passenger):\n",
    "    line = passenger\n",
    "    if re.search('Mrs', line):\n",
    "        return 'Mrs'\n",
    "    elif re.search('Mr', line):\n",
    "        return 'Mr'\n",
    "    elif re.search('Miss', line):\n",
    "        return 'Miss'\n",
    "    elif re.search('Master', line):\n",
    "        return 'Master'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "data['title'] = data['name'].apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast numerical variables as floats\n",
    "\n",
    "data['fare'] = data['fare'].astype('float')\n",
    "data['age'] = data['age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived  pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                name     sex   age  sibsp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   parch            ticket     fare cabin embarked title  \n",
       "0      0         A/5 21171   7.2500   NaN        S    Mr  \n",
       "1      0          PC 17599  71.2833   C85        C   Mrs  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  Miss  \n",
       "3      0            113803  53.1000  C123        S   Mrs  \n",
       "4      0            373450   8.0500   NaN        S    Mr  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   passengerid  891 non-null    int64  \n",
      " 1   survived     891 non-null    int64  \n",
      " 2   pclass       891 non-null    int64  \n",
      " 3   name         891 non-null    object \n",
      " 4   sex          891 non-null    object \n",
      " 5   age          714 non-null    float64\n",
      " 6   sibsp        891 non-null    int64  \n",
      " 7   parch        891 non-null    int64  \n",
      " 8   ticket       891 non-null    object \n",
      " 9   fare         891 non-null    float64\n",
      " 10  cabin        204 non-null    object \n",
      " 11  embarked     889 non-null    object \n",
      " 12  title        891 non-null    object \n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary variables\n",
    "\n",
    "features = ['pclass','survived','sex','age','sibsp','parch','fare','cabin','embarked','title']\n",
    "\n",
    "data = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'cabin', 'embarked', 'title']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_variables = [var for var in data.columns if data[var].dtype == 'object']\n",
    "cat_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pclass', 'age', 'sibsp', 'parch', 'fare']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_variables = [var for var in data.columns if var not in cat_variables and var != 'survived']\n",
    "num_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['survived']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = ['survived']\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recap of lists of variables necessary\n",
    "\n",
    "FEATURES = ['pclass','survived','sex','age','sibsp','parch','fare','cabin','embarked','title']\n",
    "\n",
    "NUMERICAL_VARIABLES = ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
    "\n",
    "CATEGORICAL_VARIABLES = ['sex', 'cabin', 'embarked', 'title']\n",
    "\n",
    "CABIN = ['cabin']\n",
    "\n",
    "TARGET = ['survived']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 9), (179, 9))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('survived', axis=1),  # predictors\n",
    "    data['survived'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test - Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B78'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['cabin'].iat[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessors\n",
    "\n",
    "### Class to extract the letter from the variable Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractLetterTransformer(BaseEstimator,TransformerMixin):\n",
    "    # Extract first letter of variable\n",
    "\n",
    "    def __init__(self, variables):\n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError('variables should be a list')\n",
    "\n",
    "        self.variables = variables\n",
    "\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for var in self.variables:\n",
    "            X[var] = X[var].apply(lambda x: x if pd.isna(x) else x[0])\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "- Impute categorical variables with string missing\n",
    "- Add a binary missing indicator to numerical variables with missing data\n",
    "- Fill NA in original numerical variable with the median\n",
    "- Extract first letter from cabin\n",
    "- Group rare Categories\n",
    "- Perform One hot encoding\n",
    "- Scale features with standard scaler\n",
    "- Fit a Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline\n",
    "titanic_pipe = Pipeline([\n",
    "\n",
    "    # ===== IMPUTATION =====\n",
    "    # impute categorical variables with string 'missing'\n",
    "    ('categorical_imputation', CategoricalImputer(\n",
    "        imputation_method='missing', variables=CATEGORICAL_VARIABLES\n",
    "    )),\n",
    "\n",
    "    # add missing indicator to numerical variables\n",
    "    ('missing_indicator', AddMissingIndicator(\n",
    "        variables= NUMERICAL_VARIABLES\n",
    "    )),\n",
    "\n",
    "    # impute numerical variables with the median\n",
    "    ('median_imputation', MeanMedianImputer(\n",
    "        imputation_method='median',variables=NUMERICAL_VARIABLES\n",
    "    )),\n",
    "\n",
    "    # Extract first letter from cabin\n",
    "    ('extract_letter', ExtractLetterTransformer(variables=CABIN)),\n",
    "\n",
    "    # == CATEGORICAL ENCODING ======\n",
    "    # remove categories present in less than 5% of the observations (0.05)\n",
    "    # group them in one category called 'Rare'\n",
    "    ('rare_label_encoder', RareLabelEncoder(\n",
    "        tol=0.05, n_categories= 1, replace_with= 'Rare',variables=CATEGORICAL_VARIABLES\n",
    "    )),\n",
    "\n",
    "    # encode categorical variables using one hot encoding into k-1 variables\n",
    "    ('categorical_encoder', OneHotEncoder(\n",
    "        drop_last= True, variables= CATEGORICAL_VARIABLES\n",
    "    )),\n",
    "\n",
    "    # scale using standardization\n",
    "    ('scaler', StandardScaler()),\n",
    "\n",
    "    # logistic regression (use C=0.0005 and random_state=0)\n",
    "    ('Logit', LogisticRegression(\n",
    "        C=0.0005, random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('categorical_imputation',\n",
       "                 CategoricalImputer(variables=['sex', 'cabin', 'embarked',\n",
       "                                               'title'])),\n",
       "                ('missing_indicator',\n",
       "                 AddMissingIndicator(variables=['pclass', 'age', 'sibsp',\n",
       "                                                'parch', 'fare'])),\n",
       "                ('median_imputation',\n",
       "                 MeanMedianImputer(variables=['pclass', 'age', 'sibsp', 'parch',\n",
       "                                              'fare'])),\n",
       "                ('extract_letter',\n",
       "                 ExtractLetterTransformer(variables=['cabin'])),\n",
       "                ('rare_label_encoder',\n",
       "                 RareLabelEncoder(n_categories=1,\n",
       "                                  variables=['sex', 'cabin', 'embarked',\n",
       "                                             'title'])),\n",
       "                ('categorical_encoder',\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=['sex', 'cabin', 'embarked',\n",
       "                                          'title'])),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('Logit', LogisticRegression(C=0.0005, random_state=0))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the pipeline\n",
    "titanic_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train roc-auc: 0.850634559062805\n",
      "train accuracy: 0.6671348314606742\n",
      "\n",
      "test roc-auc: 0.8787878787878788\n",
      "test accuracy: 0.6927374301675978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train set\n",
    "class_ = titanic_pipe.predict(X_train)\n",
    "pred = titanic_pipe.predict_proba(X_train)[:,-1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
    "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "class_ = titanic_pipe.predict(X_test)\n",
    "pred = titanic_pipe.predict_proba(X_test)[:,-1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('test roc-auc: {}'.format(roc_auc_score(y_test, pred)))\n",
    "print('test accuracy: {}'.format(accuracy_score(y_test, class_)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test - prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33781886, 0.31732847, 0.37534944, 0.53366164, 0.45728503,\n",
       "       0.37351611, 0.50044981, 0.5094244 , 0.42243567, 0.44367677,\n",
       "       0.32290034, 0.43454438, 0.32972257, 0.45032987, 0.51695348,\n",
       "       0.42816026, 0.32581688, 0.34211327, 0.32270688, 0.39057043,\n",
       "       0.33896366, 0.47252864, 0.32972096, 0.34348246, 0.42623955,\n",
       "       0.51641886, 0.32342577, 0.42594193, 0.44848604, 0.43230834,\n",
       "       0.34304995, 0.43142285, 0.32461689, 0.37419852, 0.32205951,\n",
       "       0.45309212, 0.3205385 , 0.33631577, 0.33739576, 0.36625469,\n",
       "       0.41349231, 0.34489298, 0.31820692, 0.32602003, 0.49500226,\n",
       "       0.31737214, 0.31737214, 0.55809445, 0.33388159, 0.37289922,\n",
       "       0.36482931, 0.40167255, 0.44607329, 0.32663626, 0.39445853,\n",
       "       0.34146191, 0.37158256, 0.42806874, 0.36557384, 0.32768651,\n",
       "       0.34565696, 0.4408346 , 0.4962686 , 0.40248667, 0.43525481,\n",
       "       0.33589585, 0.44209901, 0.37791414, 0.44706199, 0.5017365 ,\n",
       "       0.44414478, 0.3766087 , 0.37618173, 0.31739162, 0.3252957 ,\n",
       "       0.43725971, 0.41400243, 0.40534474, 0.32275487, 0.34969301,\n",
       "       0.32981753, 0.36623099, 0.44595016, 0.32736396, 0.33381477,\n",
       "       0.48554283, 0.50020131, 0.42043403, 0.46466228, 0.41386684,\n",
       "       0.38190875, 0.32663626, 0.40382569, 0.52902108, 0.43037551,\n",
       "       0.33687666, 0.44947118, 0.32552552, 0.37860822, 0.400167  ,\n",
       "       0.32703913, 0.36575911, 0.34759001, 0.32697299, 0.45317594,\n",
       "       0.42976093, 0.44336621, 0.44253726, 0.33704873, 0.42908613,\n",
       "       0.31949186, 0.48430647, 0.32965695, 0.4164626 , 0.40656102,\n",
       "       0.43786649, 0.42982369, 0.54293172, 0.3214583 , 0.44070781,\n",
       "       0.32354246, 0.32981384, 0.32648701, 0.38079528, 0.32327622,\n",
       "       0.40695086, 0.33687611, 0.32313641, 0.32779325, 0.36683914,\n",
       "       0.44009362, 0.32616103, 0.32504426, 0.42455588, 0.34097583,\n",
       "       0.32616103, 0.32770746, 0.424507  , 0.33228637, 0.33789927,\n",
       "       0.3366412 , 0.50501629, 0.31739162, 0.44078222, 0.43279178,\n",
       "       0.42554829, 0.33613861, 0.43914817, 0.55477186, 0.31746899,\n",
       "       0.38172342, 0.42441424, 0.42207973, 0.32414976, 0.46281717,\n",
       "       0.33681849, 0.45033647, 0.327827  , 0.4302167 , 0.4532667 ,\n",
       "       0.31737214, 0.34616636, 0.47568417, 0.42287894, 0.34753868,\n",
       "       0.34605994, 0.3186568 , 0.32588111, 0.32539951, 0.32723004,\n",
       "       0.31878287, 0.51463142, 0.31729058, 0.31820692, 0.45026982,\n",
       "       0.31739162, 0.50784342, 0.32564134, 0.32665604])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
